# Dark Science with Deep Learning: Einführung in modernes Maschinelles Lernen mit Python

Es gibt Probleme, die sind so komplex, dass das Ausprogrammieren deren Lösung entweder viel zu teuer oder momentan unmöglich wäre.
Ziel von Maschinellem Lernen (ML) als Disziplin der Künstlichen Intelligenz (KI) ist es, solche Probleme zu bewältigen, indem Systeme in erster Linie nicht programmiert, sondern trainiert werden.
Deep Learning (DL) als Teilgebiet des ML verwendet sog. tiefe neuronale Netze.
Neu ist dieser Ansatz nicht.
Neu ist hingegen der Erfolg, den heutzutage die schier grenzenlose Masse an verfügbaren Daten und die unbändige Rechenleistung möglich machen.

Mit TensorFlow und Keras bietet sich jetzt die Möglichkeit, diese hoch komplexen Netze mit wenig Aufwand zu definieren.

    
## Agenda
* Einrichtung der Entwicklungsumgebung
* Grundlagen zum Thema Künstliche Intelligenz, Maschinelles Lernen und Deep Learning
* Grundlagen zu [Tensorflow](https://www.tensorflow.org/) & [Keras](https://keras.io/)
* Übungen
   * Einführung & Arbeiten mit Daten
   * Vorhersage mit Feed-Forward-Netzen
   * Klassifikation von Bilddaten
   * Autoencoder
   * Rekurrente neuronale Netze
* Optional:
   * Parameter-Tuning
   * Custom Layers
   * Multi Modal Networks
   * ...


## Grundlagen
### Neuronale Netze
* [How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)
* [List of activation functions (equations)](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)
* [Comparison of activation functions](https://en.wikipedia.org/wiki/Activation_function)

### Convolutional Neural Networks
* [Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)

### Rekurrente neuronale Netze
* [Rekurrente neuronale Netze](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
* [Stateful LSTM in Keras](http://philipperemy.github.io/keras-stateful-lstm/)
* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)

### Autoencoders
* [Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Hilfreiche Links:
* [Jupyter Notebook Keyboard Shortcuts](https://www.cheatography.com/weidadeyue/cheat-sheets/jupyter-notebook/)
* [Managing Conda Environments](https://conda.io/docs/using/envs.html)
* [Tensorflow Playground](http://playground.tensorflow.org/)
* [NN & DL Glossary](https://deeplearning4j.org/glossary)
* [Comparing Top Deep Learning Frameworks](https://deeplearning4j.org/compare-dl4j-torch7-pylearn)
* [Deep Learning Cheat Sheet](https://github.com/kailashahirwar/cheatsheets-ai/blob/master/PDFs/Deep%20Learning%20Cheat%20Sheet-Hacker%20Noon.pdf)
* [When not to use deep learning](http://hyperparameter.space/blog/when-not-to-use-deep-learning/)
* [List of activation functions (equations)](https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications)
* [Comparison of activation functions](https://en.wikipedia.org/wiki/Activation_function)
* [L1, L2 & Max Normalization](https://stats.stackexchange.com/questions/225564/scikit-learn-normalization-mode-l1-vs-l2-max)
* [Open Data for Deep Learning](https://deeplearning4j.org/opendata)
* [First contact with TensorFlow](http://jorditorres.org/research-teaching/tensorflow/first-contact-with-tensorflow-book/first-contact-with-tensorflow/)
* [Overview of gradient descent optimization algorithms](http://ruder.io/optimizing-gradient-descent/)
* [How to choose the number of hidden layers and nodes in a feed-forward neural network?](https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw)


## Fragen & Hilfe
Sollten Sie Fragen zur Installation, Vorbereitung oder zum Workshop selbst haben, können Sie sich jederzeit an mich wenden: fabian.witt@redheads.de

## Dozenten

### Fabian Witt
Fabian Witt hat seinen Master in Data & Knowledge Engineering an der Otto-von-Guericke-Universität Magdeburg gemacht. 
In dieser Zeit hat er sich speziell mit Themen wie Maschinellem Lernen, Data Mining und Schwarmintelligenz befasst.
Bei der Firma [Redheads Ltd.](https://www.redheads.de/) ist er als Technical Lead für den Bereich Data Science verantwortlich.


### Steven Brandt
Steven Brandt arbeitet am Institutsteil Entwicklung Adaptiver Systeme des Fraunhofer IIS als Data Scientist.
Sein Aufgabengebiet ist die Entwicklung von intelligenten Analysesystemen, welche automatisch unterschiedlichste Daten verarbeiten und Handlungsempfehlungen generieren.
Zuvor erlangte Steven Brandt seinen Master in Data and Knowledge Engineering an der Otto-von-Guericke-Universität in Magdeburg.
Während des Studiums beschäftigte er sich unter anderem mit dem Maschinellen Lernen, Data Mining und Warehousing sowie Datenbanktechnologien.